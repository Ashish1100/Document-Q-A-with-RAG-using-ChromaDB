{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsVPnR8VbXE6"
   },
   "source": [
    "# Document Q&A with RAG using Chroma\n",
    "\n",
    "\n",
    "\n",
    "Two big limitations of LLMs are 1) that they only \"know\" the information that they were trained on, and 2) that they have limited input context windows. A way to address both of these limitations is to use a technique called Retrieval Augmented Generation, or RAG. A RAG system has three stages:\n",
    "\n",
    "1. Indexing\n",
    "2. Retrieval\n",
    "3. Generation\n",
    "\n",
    "Indexing happens ahead of time, and allows we to quickly look up relevant information at query-time. When a query comes in, we retrieve relevant documents, combine them with our instructions and the user's query, and have the LLM generate a tailored answer in natural language using the supplied information. This allows we to provide information that the model hasn't seen before, such as product-specific knowledge or live weather updates.\n",
    "\n",
    "In this notebook we will use the Gemini API to create a vector database, retrieve answers to questions from the database and generate a final answer. We will use [Chroma](https://docs.trychroma.com/), an open-source vector database. With Chroma, we can store embeddings alongside metadata, embed documents and queries, and search our documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akuOzK4dJl3j"
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, install ChromaDB and the Gemini API Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:29.887495Z",
     "iopub.status.busy": "2025-04-01T16:10:29.886862Z",
     "iopub.status.idle": "2025-04-01T16:10:42.858364Z",
     "shell.execute_reply": "2025-04-01T16:10:42.856806Z",
     "shell.execute_reply.started": "2025-04-01T16:10:29.887450Z"
    },
    "id": "JbXe7Oodc5dP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n",
    "!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:42.861689Z",
     "iopub.status.busy": "2025-04-01T16:10:42.861114Z",
     "iopub.status.idle": "2025-04-01T16:10:42.870195Z",
     "shell.execute_reply": "2025-04-01T16:10:42.869227Z",
     "shell.execute_reply.started": "2025-04-01T16:10:42.861629Z"
    },
    "id": "muuhsDmmKdHi",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQOGMejVu-6D"
   },
   "source": [
    "### Set up our API key\n",
    "\n",
    "To run the following cell, our API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
    "\n",
    "If we don't already have an API key, we can grab one from [AI Studio](https://aistudio.google.com/app/apikey). We can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
    "\n",
    "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add our key or enable it for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:42.871776Z",
     "iopub.status.busy": "2025-04-01T16:10:42.871391Z",
     "iopub.status.idle": "2025-04-01T16:10:43.273378Z",
     "shell.execute_reply": "2025-04-01T16:10:43.272331Z",
     "shell.execute_reply.started": "2025-04-01T16:10:42.871735Z"
    },
    "id": "ysayz8skEfBW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52b101760a45"
   },
   "source": [
    "If we received an error response along the lines of `No user secrets exist for kernel id ...`, then we need to add our API key via `Add-ons`, `Secrets` **and** enable it.\n",
    "\n",
    "![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fegnGFpMS4AI"
   },
   "source": [
    "### Explore available models\n",
    "\n",
    "Using the [`embedContent`](https://ai.google.dev/api/embeddings#method:-models.embedcontent) API method to calculate embeddings in this guide. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. We can also find more information about the embedding models on [the models page](https://ai.google.dev/gemini-api/docs/models/gemini#text-embedding).\n",
    "\n",
    "`text-embedding-004` is the most recent generally-available embedding model, so we will use it for this exercise, but try out the experimental `gemini-embedding-exp-03-07` model too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:43.275083Z",
     "iopub.status.busy": "2025-04-01T16:10:43.274761Z",
     "iopub.status.idle": "2025-04-01T16:10:44.240026Z",
     "shell.execute_reply": "2025-04-01T16:10:44.239036Z",
     "shell.execute_reply.started": "2025-04-01T16:10:43.275052Z"
    },
    "id": "Km5d13_FS2Q_",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "for m in client.models.list():\n",
    "    if \"embedContent\" in m.supported_actions:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XWKXoXwOGxS"
   },
   "source": [
    "### Data\n",
    "\n",
    "Here is a small set of documents we will use to create an embedding database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:44.241590Z",
     "iopub.status.busy": "2025-04-01T16:10:44.241260Z",
     "iopub.status.idle": "2025-04-01T16:10:44.247033Z",
     "shell.execute_reply": "2025-04-01T16:10:44.246033Z",
     "shell.execute_reply.started": "2025-04-01T16:10:44.241558Z"
    },
    "id": "k8nsbhFJKmG-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DOCUMENT1 = \"Operating the Climate Control System  Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"\n",
    "DOCUMENT2 = 'Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.'\n",
    "DOCUMENT3 = \"Shifting Gears Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"\n",
    "\n",
    "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDzxArLeOexD"
   },
   "source": [
    "## Creating the embedding database with ChromaDB\n",
    "\n",
    "Create a [custom function](https://docs.trychroma.com/guides/embeddings#custom-embedding-functions) to generate embeddings with the Gemini API. In this task, we are implementing a retrieval system, so the `task_type` for generating the *document* embeddings is `retrieval_document`. Later, we will use `retrieval_query` for the *query* embeddings. Check out the [API reference](https://ai.google.dev/api/embeddings#v1beta.TaskType) for the full list of supported tasks.\n",
    "\n",
    "Keywords: Documents are the items that are in the database. They are inserted first, and later retrieved. Queries are the textual search terms and can be simple keywords or textual descriptions of the desired documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:44.249456Z",
     "iopub.status.busy": "2025-04-01T16:10:44.248538Z",
     "iopub.status.idle": "2025-04-01T16:10:44.262337Z",
     "shell.execute_reply": "2025-04-01T16:10:44.261413Z",
     "shell.execute_reply.started": "2025-04-01T16:10:44.249407Z"
    },
    "id": "mF7Uu1kCQsT0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    document_mode = True\n",
    "\n",
    "    @retry.Retry(predicate=is_retriable)\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        response = client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(\n",
    "                task_type=embedding_task,\n",
    "            ),\n",
    "        )\n",
    "        return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrDWLyopPNBf"
   },
   "source": [
    "Now create a [Chroma database client](https://docs.trychroma.com/getting-started) that uses the `GeminiEmbeddingFunction` and populate the database with the documents we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:44.263833Z",
     "iopub.status.busy": "2025-04-01T16:10:44.263521Z",
     "iopub.status.idle": "2025-04-01T16:10:44.600997Z",
     "shell.execute_reply": "2025-04-01T16:10:44.600141Z",
     "shell.execute_reply.started": "2025-04-01T16:10:44.263800Z"
    },
    "id": "OITXgxZlLoXU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "DB_NAME = \"googlecardb\"\n",
    "\n",
    "embed_fn = GeminiEmbeddingFunction()\n",
    "embed_fn.document_mode = True\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "db.add(documents=documents, ids=[str(i) for i in range(len(documents))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QbwFgfXp-fL"
   },
   "source": [
    "Confirm that the data was inserted by looking at the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:44.602798Z",
     "iopub.status.busy": "2025-04-01T16:10:44.602382Z",
     "iopub.status.idle": "2025-04-01T16:10:44.612215Z",
     "shell.execute_reply": "2025-04-01T16:10:44.611183Z",
     "shell.execute_reply.started": "2025-04-01T16:10:44.602756Z"
    },
    "id": "kQ9PHUL_l-hf",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.count()\n",
    "# You can peek at the data too.\n",
    "# db.peek(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu5zRErgsQ8u"
   },
   "source": [
    "## Retrieval: Find relevant documents\n",
    "\n",
    "To search the Chroma database, call the `query` method. Note that we also switch to the `retrieval_query` mode of embedding generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:44.613679Z",
     "iopub.status.busy": "2025-04-01T16:10:44.613398Z",
     "iopub.status.idle": "2025-04-01T16:10:45.379334Z",
     "shell.execute_reply": "2025-04-01T16:10:45.378242Z",
     "shell.execute_reply.started": "2025-04-01T16:10:44.613651Z"
    },
    "id": "gQdJMbTSLtKE",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch to query mode when generating embeddings.\n",
    "embed_fn.document_mode = False\n",
    "\n",
    "# Search the Chroma DB using the specified query.\n",
    "query = \"How do you use the touchscreen to play music?\"\n",
    "\n",
    "result = db.query(query_texts=[query], n_results=1)\n",
    "[all_passages] = result[\"documents\"]\n",
    "\n",
    "Markdown(all_passages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8PNRMpOQkm5"
   },
   "source": [
    "## Augmented generation: Answer the question\n",
    "\n",
    "Now that we have found a relevant passage from the set of documents (the *retrieval* step), we can now assemble a generation prompt to have the Gemini API *generate* a final answer. Note that in this example only a single passage was retrieved. In practice, especially when the size of our underlying data is large, we will want to retrieve more than one result and let the Gemini model determine what passages are relevant in answering the question. For this reason it's OK if some retrieved passages are not directly related to the question - this generation step should ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:45.380917Z",
     "iopub.status.busy": "2025-04-01T16:10:45.380584Z",
     "iopub.status.idle": "2025-04-01T16:10:45.387350Z",
     "shell.execute_reply": "2025-04-01T16:10:45.386160Z",
     "shell.execute_reply.started": "2025-04-01T16:10:45.380875Z"
    },
    "id": "b6_Y-GOymaXu",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
      "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
      "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
      "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
      "\n",
      "QUESTION: How do you use the touchscreen to play music?\n",
      "PASSAGE: Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_oneline = query.replace(\"\\n\", \" \")\n",
    "\n",
    "# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
    "prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
    "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
    "\n",
    "QUESTION: {query_oneline}\n",
    "\"\"\"\n",
    "\n",
    "# Add the retrieved documents to the prompt.\n",
    "for passage in all_passages:\n",
    "    passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "    prompt += f\"PASSAGE: {passage_oneline}\\n\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRy6yXzcPxLB"
   },
   "source": [
    "Now use the `generate_content` method to to generate an answer to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:10:45.389012Z",
     "iopub.status.busy": "2025-04-01T16:10:45.388625Z",
     "iopub.status.idle": "2025-04-01T16:10:46.177941Z",
     "shell.execute_reply": "2025-04-01T16:10:46.176999Z",
     "shell.execute_reply.started": "2025-04-01T16:10:45.388979Z"
    },
    "id": "EwfyxFM6Giy9",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To play music on your Googlecar, you can use the large touchscreen display by simply touching the \"Music\" icon, which will then allow you to play your favorite songs.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt)\n",
    "\n",
    "Markdown(answer.text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day-2-document-q-a-with-rag.ipynb",
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
